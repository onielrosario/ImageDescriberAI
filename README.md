[![Swift](https://img.shields.io/badge/Swift-5.9-orange)](https://swift.org)
[![Tuist](https://img.shields.io/badge/Tuist-Modular-blue)](https://tuist.io)
[![iOS](https://img.shields.io/badge/iOS-16+-lightgrey)](https://developer.apple.com/ios/)

<img src="https://github.com/user-attachments/assets/590f4ebb-2f0a-45ba-a111-c5a73c780384" alt="Hero Banner" width="100%" />

# ğŸ§  ImageDescriberAI

Effortlessly turn images into natural language descriptions using OpenAIâ€™s GPT-4o vision model. Built with SwiftUI, Cloudinary, and a scalable backend proxyâ€”ready for real-world use and distribution.

---

## âœ¨ Features

- ğŸ“¸ Native SwiftUI interface with Photos picker
- ğŸ§  Vision-powered GPT-4o AI descriptions
- âš¡ï¸ Secure image uploads via **Cloudinary**
- ğŸ” OpenAI API access via Vercel proxy (no key in app)
- ğŸ§± Modular Tuist-based architecture (MVVM)
- âœ… Responsive loading/error states + debounced scanning
- ğŸ“¦ Seamless TestFlight automation with Fastlane + GitHub Actions

---

## ğŸ“· How It Works

1. Select an image from your library
2. The image is uploaded to Cloudinary
3. The Cloudinary URL is sent to a **Vercel proxy**
4. The proxy securely talks to OpenAIâ€™s `gpt-4o` model
5. A natural-language description is returned and displayed in-app

---

## ğŸ›  Architecture

- **SwiftUI + MVVM**
- **Tuist Modular Design**
- **Backend Proxy (Vercel)** for secure key handling
- **Cloudinary SDK** integration for image hosting
- **Main Modules:**
  - `ImageDescriberAI` (App entry)
  - `ImageScannerUI`
  - `ImageAnalysis`
  - `AIDescriptionService`
  - `SharedModels`
  - `ImageUploader`
  - `OpenAIProvider`

---

## ğŸ” Secrets / API Keys

The app does **not** expose OpenAI keys. Keys are securely used in the backend proxy.

For local testing, the project uses `.env`:

```env
OPENAI_API_KEY=your-api-key-here


- Copy `.env.example` to `.env`
- Add your OpenAI key
- `.env` is listed in `.gitignore`
- During debug, the file must be copied into the app bundle manually
- During CI builds, a dummy `.env` is injected automatically
```

---

## ğŸš€ Getting Started

This project uses Tuist for project generation and includes CI automation:

```bash
# 1. Clone this repo
# 2. Install Tuist
brew install tuist

# 3. Generate the project
cd ImageDescriberAI
tuist generate

# 4. Tuist usually opens the project automatically. But if not, open the workspace:
open ImageDescriberAI.xcworkspace
```

---

## ğŸ§ª CI Pipeline

TestFlight deployment is automated using GitHub Actions + Fastlane:

- ğŸ— Builds and tests on `macos-latest`
- âœ… Automatically disables code signing
- ğŸ“¦ Injects a dummy `.env` value for testing and builds and pushes to TestFlight on tag push (e.g. v1.0.0-testflight)
  Example:
   ```
  on:
  push:
    tags:
      - 'v*.*.*-testflight'
   ```
- ğŸ§¼ Cleans derived data for consistency
- ğŸ” Secrets handled with GitHub Actions encrypted secrets
- ğŸ” Uses `xcodebuild` with inline build flags:

```bash
xcodebuild build-for-testing \  
  CODE_SIGNING_ALLOWED=NO CODE_SIGNING_REQUIRED=NO CODE_SIGN_IDENTITY=""
```

> âš ï¸ Note: Do not define these variables separately with backslashes (`\`) across lines.  
They must be **inline build settings**, or they will be ignored.

---

## ğŸ“¦ Future Enhancements

- ğŸ”„ Usage-based scan credits
- ğŸ›’ In-app purchases via StoreKit or Stripe
- ğŸ§  Scan history and logging
- ğŸŒ Multilingual support
- ğŸ§¼ Offline caching of results

---

## ğŸ“¸ Demo & Screenshots

*Coming soon: demo of image selection â†’ AI description.*

---

## ğŸ§ª Testing & Contribution

- Unit testing is supported through the `ImageDescriberAITests` target
- Modular design makes mocking and test injection easy

### ğŸ‘¥ Contributing

PRs welcome! If you find a bug or want to propose an improvement, open an issue or submit a pull request. Let's make it better together.

---

## ğŸ‘¨â€ğŸ’» Built By

**Oniel Rosario** â€“ iOS Engineer | AI Explorer | Modular Design Enthusiast

Have ideas, feedback, or want to collaborate? Feel free to reach out or contribute âœŒï¸



